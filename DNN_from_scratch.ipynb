{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "DNN_from_scratch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kyle-gao/DNN_from_scratch/blob/master/DNN_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TkhCMZeh20J",
        "colab_type": "text"
      },
      "source": [
        "Copyright 2020 Yi Lin(Kyle) Gao\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 .\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC3U6JKZvI2I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1c48a8c2-cc3c-4fd8-db07-ac4653c6377f"
      },
      "source": [
        "!pip install mnist"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mnist in /usr/local/lib/python3.6/dist-packages (0.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mnist) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-I0lcgJn53u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import mnist\n",
        "import copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Z49ylH9rJHi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_X = mnist.train_images()/255.0\n",
        "train_Y = mnist.train_labels()\n",
        "\n",
        "test_X = mnist.test_images()/255.0\n",
        "test_Y = mnist.test_labels()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uvjwvq87n53y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "0df4410c-277f-4938-b8a4-b3807b6813d1"
      },
      "source": [
        "id = 6\n",
        "train_X=np.reshape(train_X,(-1,28*28))\n",
        "test_X=np.reshape(test_X,(-1,28*28))\n",
        "firstX=train_X[id,:]\n",
        "firstX=np.reshape(firstX,(28,28))\n",
        "plt.imshow(firstX)\n",
        "print(np.shape(train_X))\n",
        "print(train_Y[id])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAMB0lEQVR4nO3dbYwdZRnG8euyLq3UElvR2mCjQAoKRopsqlE0KBFLP1iICVINqUnN8qFESDCRoAl8JL5gNCEmq1Sq0RoUCDUhSqlEwgdIF1L6Ki1ikdbSlVSlmFiW9vbDTnGBPbPbMzNnjnv/f8nJmfM8c/a5M+nVed19HBECMPO9pe0CAPQGYQeSIOxAEoQdSIKwA0m8tZeDneLZMUdzezkkkMp/9G+9Ekc9WV+lsNteLukHkmZJ+klE3Fa2/hzN1Ud9aZUhAZR4PDZ37Ov6MN72LEl3SLpc0nmSVtk+r9ufB6BZVc7Zl0l6JiKejYhXJP1K0sp6ygJQtyphP0PS8xM+7y/aXsf2kO0R2yNjOlphOABVNH41PiKGI2IwIgYHNLvp4QB0UCXsByQtnvD5vUUbgD5UJexbJC2xfabtUyRdLWljPWUBqFvXt94i4lXb10n6vcZvva2LiJ21VQagVpXus0fEA5IeqKkWAA3icVkgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkujplM3ovT0/vai0/y+fu7O0//bDZ5X2P3TVYGn/sV17SvvRO+zZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJ7rPPALPOP7dj3/2fvqP0u2MxUNq/dv7Tpf2/+fBlpf3zdpV2o4cqhd32PklHJB2T9GpElD9hAaA1dezZPx0RL9bwcwA0iHN2IImqYQ9JD9p+wvbQZCvYHrI9YntkTEcrDgegW1UP4y+OiAO23y1pk+0/RcQjE1eIiGFJw5J0mhdExfEAdKnSnj0iDhTvo5Luk7SsjqIA1K/rsNuea3veiWVJl0naUVdhAOpV5TB+oaT7bJ/4Ob+MiN/VUhVOzoEXOnZ9bc/VpV/ddP49dVeDPtV12CPiWUkX1FgLgAZx6w1IgrADSRB2IAnCDiRB2IEk+BXXGeDYP//Vse+5/UvKv3x+zcWgb7FnB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkuM8+A8xa+O6OfZ/8IFMmYxx7diAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgvvsM8G8uR27VizY0ujQoxe5tP8d287p2HdsF88A9BJ7diAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgvvsM8CxZ/7Sse9bv/1i6Xe/sOqOSmPv/NIPS/sv/Nf1HfsWc5+9p6bcs9teZ3vU9o4JbQtsb7K9t3if32yZAKqazmH8XZKWv6HtJkmbI2KJpM3FZwB9bMqwR8Qjkg6/oXmlpPXF8npJV9RcF4CadXvOvjAiDhbLL0ha2GlF20OShiRpjk7tcjgAVVW+Gh8RISlK+ocjYjAiBgc0u+pwALrUbdgP2V4kScX7aH0lAWhCt2HfKGl1sbxa0v31lAOgKVOes9veIOkSSafb3i/pFkm3Sbrb9hpJz0m6qski0b2zv/5Y+QqrelMH2jdl2COi0z+HS2uuBUCDeFwWSIKwA0kQdiAJwg4kQdiBJPgV1+QGPKu0f6zjs5H4f8OeHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeS4D57cmNxrLT/uI73qBI0jT07kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSSmDLvtdbZHbe+Y0Har7QO2txavFc2WCaCq6ezZ75K0fJL270fE0uL1QL1lAajblGGPiEckHe5BLQAaVOWc/Trb24rD/PmdVrI9ZHvE9siYjlYYDkAV3Yb9R5LOlrRU0kFJ3+u0YkQMR8RgRAwOaHaXwwGoqquwR8ShiDgWEccl/VjSsnrLAlC3rsJue9GEj1dK2tFpXQD9Ycq/G297g6RLJJ1ue7+kWyRdYnuppJC0T9K1DdaIBjU9P/tpHx+t9gNQmynDHhGrJmm+s4FaADSIJ+iAJAg7kARhB5Ig7EAShB1Igimbk2t6yuY/XrChY9/nP7am/MuPbas0Nl6PPTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJMF99uQ+8Ievlvbv+sxwY2PvGTqltP+cxxobOiX27EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBPfZk5u9523lK3ymN3WgeezZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJR1Sck/cknOYF8VFf2rPxUN2qP/2ttP/L8w52/bOnmi768ssnm0D4f44/tbvrsWeqx2OzXorDnqxvyj277cW2H7a9y/ZO29cX7Qtsb7K9t3ifX3fhAOozncP4VyXdGBHnSfqYpLW2z5N0k6TNEbFE0ubiM4A+NWXYI+JgRDxZLB+RtFvSGZJWSlpfrLZe0hVNFQmgupN6Nt72+yVdKOlxSQsj4sQJ2wuSFnb4zpCkIUmao1O7rRNARdO+Gm/77ZLukXRDRLw0sS/Gr/JNeqUvIoYjYjAiBgc0u1KxALo3rbDbHtB40H8REfcWzYdsLyr6F0kabaZEAHWY8jDetiXdKWl3RNw+oWujpNWSbive72+kQrTqrr9+vLR/1fm/7vpnj/Xuri80vXP2T0i6RtJ221uLtps1HvK7ba+R9Jykq5opEUAdpgx7RDwqadKb9JJ4Qgb4P8HjskAShB1IgrADSRB2IAnCDiTBn5JGqaN3vad8he/0pg5Ux54dSIKwA0kQdiAJwg4kQdiBJAg7kARhB5LgPjtKzd96uLT/jn+cW9q/dv7TdZaDCtizA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASTNkMzCCVpmwGMDMQdiAJwg4kQdiBJAg7kARhB5Ig7EASU4bd9mLbD9veZXun7euL9lttH7C9tXitaL5cAN2azh+veFXSjRHxpO15kp6wvano+35EfLe58gDUZTrzsx+UdLBYPmJ7t6Qzmi4MQL1O6pzd9vslXSjp8aLpOtvbbK+zPb/Dd4Zsj9geGdPRSsUC6N60w2777ZLukXRDRLwk6UeSzpa0VON7/u9N9r2IGI6IwYgYHNDsGkoG0I1phd32gMaD/ouIuFeSIuJQRByLiOOSfixpWXNlAqhqOlfjLelOSbsj4vYJ7YsmrHalpB31lwegLtO5Gv8JSddI2m57a9F2s6RVtpdKCkn7JF3bSIUAajGdq/GPSprs92MfqL8cAE3hCTogCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASPZ2y2fbfJT03oel0SS/2rICT06+19WtdErV1q87a3hcR75qso6dhf9Pg9khEDLZWQIl+ra1f65KorVu9qo3DeCAJwg4k0XbYh1sev0y/1tavdUnU1q2e1NbqOTuA3ml7zw6gRwg7kEQrYbe93PbTtp+xfVMbNXRie5/t7cU01CMt17LO9qjtHRPaFtjeZHtv8T7pHHst1dYX03iXTDPe6rZre/rznp+z254laY+kz0raL2mLpFURsaunhXRge5+kwYho/QEM25+S9LKkn0XEh4q2b0s6HBG3Ff9Rzo+Ib/RJbbdKerntabyL2YoWTZxmXNIVkr6iFrddSV1XqQfbrY09+zJJz0TEsxHxiqRfSVrZQh19LyIekXT4Dc0rJa0vltdr/B9Lz3WorS9ExMGIeLJYPiLpxDTjrW67krp6oo2wnyHp+Qmf96u/5nsPSQ/afsL2UNvFTGJhRBwsll+QtLDNYiYx5TTevfSGacb7Ztt1M/15VVyge7OLI+Ijki6XtLY4XO1LMX4O1k/3Tqc1jXevTDLN+Gva3HbdTn9eVRthPyBp8YTP7y3a+kJEHCjeRyXdp/6bivrQiRl0i/fRlut5TT9N4z3ZNOPqg23X5vTnbYR9i6Qlts+0fYqkqyVtbKGON7E9t7hwIttzJV2m/puKeqOk1cXyakn3t1jL6/TLNN6dphlXy9uu9enPI6LnL0krNH5F/s+SvtlGDR3qOkvSU8VrZ9u1Sdqg8cO6MY1f21gj6Z2SNkvaK+khSQv6qLafS9ouaZvGg7Wopdou1vgh+jZJW4vXira3XUldPdluPC4LJMEFOiAJwg4kQdiBJAg7kARhB5Ig7EAShB1I4r/duaskOkNYmQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wq8Tm2OQn537",
        "colab_type": "text"
      },
      "source": [
        "Sigmoid and derivative"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJzLrNwtn538",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(Z):\n",
        "    #sigmoid function\n",
        "    return  1/(1+np.exp(-Z))\n",
        "\n",
        "def dsigmoid(Z):\n",
        "    #sigmoid derivative\n",
        "    return sigmoid(Z)*(1-sigmoid(Z))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSttRzPGn54B",
        "colab_type": "text"
      },
      "source": [
        "RelU and derivative"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0okNNuibn54C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def relu(Z):\n",
        "    #returns the element-wise relu of Z, fast implementation\n",
        "    #Z -- an array of floats\n",
        "    return Z * (Z > 0)\n",
        "\n",
        "def drelu(Z):\n",
        "    #relu derivative\n",
        "    return 1. * (Z > 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yv9jLHuVn54F",
        "colab_type": "text"
      },
      "source": [
        "Softmax and derivative"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USlVRFLAn54G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax(Z,eps=1e-10):\n",
        "    \"\"\"Numerically stable softmax\n",
        "    Given (m,n) input, returns softmax over the last dimension\"\"\"\n",
        "    shiftZ = Z - np.max(Z,axis=-1,keepdims=True)\n",
        "    expZ=np.exp(shiftZ)\n",
        "    total=np.sum(expZ,axis=-1,keepdims=True)+eps\n",
        "    return expZ/total\n",
        "\n",
        "\n",
        "def dsoftmax(Z):\n",
        "    \"\"\"Given a (m,n) matrix, returns a (m,n,n) jacobian matrix\"\"\"\n",
        "    m,n=np.shape(Z)\n",
        "    softZ=(softmax(Z))\n",
        "    prodtensor=np.einsum(\"ij,ik->ijk\",softZ,softZ)\n",
        "    diagtensor=np.einsum('ij,jk->ijk', softZ, np.eye(n, n))\n",
        "    return diagtensor-prodtensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biGHmwhVsY9l",
        "colab_type": "text"
      },
      "source": [
        "Derivative Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoBFmtg8n534",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "84b30182-9a0b-43f6-ff7a-7dade0738668"
      },
      "source": [
        "def test_derivative(func,z,eps=1e-8):\n",
        "    \"\"\"2 sided derivative for single valued function or 'hadamard product type' function\"\"\"\n",
        "    return (func(z+eps)-func(z-eps))/(2*eps)\n",
        "\n",
        "def test_jac(func,Z,eps=1e-8):\n",
        "    \"\"\"Returns the jacobian (m,n,n) of a matrix function f:(m,n)->(m,n) \n",
        "        (jacobian over the second input axis 'n', 'm' is ignore)\"\"\"\n",
        "    m,n=np.shape(Z)\n",
        "    jacobian=np.zeros((m,n,n))\n",
        "    for idx, ij in np.ndenumerate(Z):\n",
        "        epsM=np.zeros((m,n))\n",
        "        epsM[idx]=eps\n",
        "        jacobian[idx[0],idx[1],:]=((func(Z+epsM)-func(Z-epsM))/(2*eps))[idx[0],:]\n",
        "    return jacobian\n",
        "\n",
        "\n",
        "\"\"\"#Test sigmoid\n",
        "z=np.random.rand(5,3)\n",
        "print(test_derivative(sigmoid,z)-dsigmoid(z))\"\"\"\n",
        "\n",
        "\"\"\"#Test relu\n",
        "z=np.random.rand(5,3)\n",
        "\n",
        "print(test_derivative(sigmoid,z)-dsigmoid(z))\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "#Test softmax\n",
        "Z= np.random.rand(5,3)\n",
        "print(np.isclose(test_jac(softmax,Z)-dsoftmax(Z),0,1e-8))\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n#Test softmax\\nZ= np.random.rand(5,3)\\nprint(np.isclose(test_jac(softmax,Z)-dsoftmax(Z),0,1e-8))'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOL1HVqHn54K",
        "colab_type": "text"
      },
      "source": [
        "One hot encodding and loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSGfKX9In54K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a4b6491d-eed8-480b-f80b-4e60fd0cf07e"
      },
      "source": [
        "def one_hot(Y,n_class):\n",
        "    #Y -- (m,) array of classes from (0 to n_class)\n",
        "    #n_class -- an integer representing the number of classes\n",
        "    \"\"\"Returns the one_hot representation (m,n_class)\"\"\"\n",
        "    m=np.shape(Y)[0]\n",
        "    \n",
        "    O_h=np.zeros((m,n_class))\n",
        "    O_h[range(m),Y]=1\n",
        "    \n",
        "    return O_h\n",
        "\n",
        "\"\"\"\n",
        "#Test\n",
        "ytest=train_Y[0:5]\n",
        "print(one_hot(ytest,10))\n",
        "print(train_Y[0:5])\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n#Test\\nytest=train_Y[0:5]\\nprint(one_hot(ytest,10))\\nprint(train_Y[0:5])'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWgKb_RIsqpf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_Y_oh=one_hot(train_Y,10)\n",
        "test_Y_oh=one_hot(test_Y,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPnfSfkPn54O",
        "colab_type": "text"
      },
      "source": [
        "Loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raq6gy6yn54O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def categorical_crossentropy(Y,Yhat,eps=1e-8):\n",
        "    #Y -- (m,dim_y) array of labels m=examples \n",
        "    #Yhat -- (m,dim_y) array of logits\n",
        "    \"\"\"Computes the categorical cross-entropy for one hot encoded labels\"\"\"\n",
        "    m,dimy=np.shape(Y)\n",
        "    Yhat=np.clip(Yhat,eps,1-eps) #for numerical stability if this is used, the output of the last layer must be normalized \n",
        "\n",
        "    #J=-(Y*np.log(Yhat)+(1-Y)*np.log(1-Yhat))\n",
        "    J=-np.sum(Y*np.log(Yhat),axis=-1)\n",
        "    #J=np.sum((Y-Yhat)*(Y-Yhat),axis=0)\n",
        "    \n",
        "    return np.sum(J,axis=0)/(m)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4VzGIKsn54R",
        "colab_type": "text"
      },
      "source": [
        "Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTL-cFiUn54R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_rand_minibatch(X, Y, minibatch_size = 64):\n",
        "    #inputs\n",
        "    #X -- ( m,dim_x) array of labelled data \n",
        "    #Y -- (m,dim_y) array of labels\n",
        "    #minibatch_size -- int, minibatch size\n",
        "    #outputs\n",
        "    #minibatches -- list of (X,Y), a list of tuple (miniX,miniY) of randomly shuffled minibatches\n",
        "    \n",
        "    m=X.shape[0]\n",
        "    minibatches=[]\n",
        "    \n",
        "    rand_perm=np.random.permutation(m)\n",
        "    shuffled_X=X[rand_perm,:]\n",
        "    shuffled_Y=Y[rand_perm]\n",
        "    num_batches=int(np.floor(m/minibatch_size))\n",
        "    \n",
        "    for b in range(num_batches):\n",
        "        mini_X=shuffled_X[b*minibatch_size:(b+1)*minibatch_size,:]\n",
        "        mini_Y=shuffled_Y[b*minibatch_size:(b+1)*minibatch_size]\n",
        "        minibatches.append((mini_X,mini_Y))\n",
        "    if m%minibatch_size !=0: #left over minibatch\n",
        "        mini_X=shuffled_X[num_batches*minibatch_size:,:]\n",
        "        mini_Y=shuffled_Y[num_batches*minibatch_size:]\n",
        "        minibatches.append((mini_X,mini_Y))\n",
        "    \n",
        "    return minibatches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9G0-9LJn54X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_parameters(layers):\n",
        "    #input\n",
        "    #layers -- list of int:layer sizes, note: layer[0] is input layer, layer[L] is output layer\n",
        "    \n",
        "    #output\n",
        "    #Ws,Bs -- lists of np arrays, the randomly initialized weights and zero initialized biases\n",
        "    \n",
        "    L=len(layers)\n",
        "    Ws=[]\n",
        "    Bs=[]\n",
        "    \n",
        "    for l in range(1,L):\n",
        "        wl=np.random.randn(layers[l-1],layers[l])\n",
        "        bl=np.zeros((layers[l],1))\n",
        "        Ws.append(wl)\n",
        "        Bs.append(bl)\n",
        "    return Ws,Bs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJVYN9-MsyfQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Test\n",
        "layers=[784,12,11,10]\n",
        "Ws,bs=initialize_parameters(layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27yYbWgPn54Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward(A_prev,W,b,activation='relu'):\n",
        "    #A_prev -- (m,dim_a_prev) \n",
        "    #W -- (dim_a,dim_a_prev)\n",
        "    #b -- (dim_a,1)\n",
        "    #activation -- a function (relu,sigmoid,softmax)\n",
        "    Z=np.dot(A_prev,W)+b.T\n",
        "    if activation=='relu':\n",
        "        A_next=relu(Z)\n",
        "    elif activation=='sigmoid':\n",
        "        A_next=sigmoid(Z)\n",
        "    elif activation=='linear':\n",
        "        A_next=Z\n",
        "    elif activation=='softmax':\n",
        "        A_next=softmax(Z)\n",
        "    else:\n",
        "        A_next=None\n",
        "        print('Activation not recognized')\n",
        "    \n",
        "    return A_next,Z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jUgccM4qB0x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "20ebcea3-c48a-4c88-e1f6-e6293f975682"
      },
      "source": [
        "#Test\n",
        "A=np.random.rand(500,10)\n",
        "W=np.random.randn(10,5)\n",
        "b=np.random.randn(5,1)\n",
        "Anext,__=forward(A,W,b)\n",
        "print(np.shape(Anext))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(500, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ohi4HSxtn54b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def backward(dA,W,A_prev,Z,activation=\"relu\"):\n",
        "    #dA -- (m,dim_a) np.array\n",
        "    #W -- dim (dim_a,dim_a_prev) np.array\n",
        "    #A_prev -- (m,dim_a_prev) np.array\n",
        "    #Z -- (m,dim_a) np.array\n",
        "    m=A_prev.shape[0]\n",
        "    \n",
        "    if activation=='relu':\n",
        "        dZ=dA*drelu(Z)\n",
        "    elif activation=='sigmoid':\n",
        "        dZ=dA*dsigmoid(Z)\n",
        "    elif activation=='linear':\n",
        "        dZ=dA\n",
        "    elif activation=='softmax': #Can absorb the derivative of the softmax into the derivative of the loss function\n",
        "        dZ=np.einsum(\"ijk,ij->ik\",dsoftmax(Z),dA)\n",
        "    else:\n",
        "        A_next=None\n",
        "        print('back Activation not recognized')\n",
        "        \n",
        "    dA_prev=np.dot(dZ,W.T)\n",
        "    dW=np.dot(A_prev.T,dZ)/m\n",
        "    dB=np.mean(dZ,axis=0)\n",
        "    dB=np.reshape(dB,(len(dB),1))\n",
        "    return dA_prev, dW, dB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbyPjYdUqAny",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "89e9d992-987a-4695-f351-2ab827edd1dc"
      },
      "source": [
        "#Test\n",
        "dA=np.ones((10,6))\n",
        "W=np.ones((5,6))\n",
        "A_prev=np.ones((10,5))\n",
        "Z=np.ones((10,6))\n",
        "da_prev,dW,dB=backward(dA,W,A_prev,Z,activation=\"relu\")\n",
        "print(dW)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1.]\n",
            " [1. 1. 1. 1. 1. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0Tj119Dn54g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_prop(Ws,Bs,X,middle_activations='relu',last_activation='softmax'):\n",
        "    \n",
        "    #inputs:\n",
        "    #Ws -- list of weights\n",
        "    #Bs -- list of biases\n",
        "    #X -- input layer\n",
        "    \n",
        "    #output\n",
        "    #As -- list of (n_a,m) arrays of activations\n",
        "    \n",
        "    As=[]\n",
        "    Zs=[None]\n",
        "    As.append(X)\n",
        "    L=len(Ws)\n",
        "    \n",
        "    \n",
        "    for i in range(L-1):\n",
        "        Anext,Znext=forward(As[-1],Ws[i],Bs[i],middle_activations)\n",
        "        As.append(Anext)\n",
        "        Zs.append(Znext)\n",
        "    Anext,Znext=forward(As[-1],Ws[L-1],Bs[L-1],last_activation)\n",
        "    As.append(Anext)\n",
        "    Zs.append(Znext)\n",
        "   # Anext,Znext=forward(As[-1],Ws[L-1],Bs[L-1],'softmax')\n",
        "   # As.append(Anext)\n",
        "   # Zs.append(Znext)\n",
        "    \n",
        "    return As,Zs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sk-rvc0n54k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c9432d9f-d18c-4f7b-bdbe-1cfd6469d353"
      },
      "source": [
        "#Test\n",
        "X_test=train_X[0:20,:]\n",
        "Y_test=train_Y_oh[0:20]\n",
        "As,Zs=forward_prop(Ws,bs,X_test)\n",
        "np.shape(As[-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viXCaLC2n54n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def back_prop(Ws,As,Y,Zs,middle_activations='relu',last_activation='softmax'):\n",
        "    dAs=[]\n",
        "    dWs=[]\n",
        "    dBs=[]\n",
        "   \n",
        "    L=len(Ws)\n",
        "    \n",
        "    #The softmax derivative dL/dWij=dL/dai dai/dWij = (Y-A)*dZ which has the same form as the sigmoid derivative\n",
        "    dA=As[-1]-Y \n",
        "    if last_activation=='softmax':\n",
        "        last_activation='linear'\n",
        "    dA, dW, dB=backward(dA,Ws[L-1],As[L-1],Zs[L],last_activation)\n",
        "    #The linear backward layer takes into account both softmax and sigmoid final layers. \n",
        "    \n",
        "    dWs.append(dW)\n",
        "    dBs.append(dB)    \n",
        "    for i in range(L-2,-1,-1):\n",
        "        dA_prev, dW, dB=backward(dA,Ws[i],As[i],Zs[i+1],middle_activations)\n",
        "        dWs.append(dW)\n",
        "        dBs.append(dB)\n",
        "        dA=dA_prev\n",
        "    dWs.reverse()\n",
        "    dBs.reverse()\n",
        "    return dWs,dBs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aw0PNet_n54q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "84fcb078-5475-4b20-a612-67d339abafd0"
      },
      "source": [
        "#Test\n",
        "dWs,dBs=back_prop(Ws,As,train_Y_oh[0:20],Zs)\n",
        "for dw in dWs:\n",
        "    print(np.shape(dw))\n",
        "for w in Ws:\n",
        "    print(np.shape(w))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(784, 12)\n",
            "(12, 11)\n",
            "(11, 10)\n",
            "(784, 12)\n",
            "(12, 11)\n",
            "(11, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bn5_tu2ln54u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def optmize(Ws,Bs,dWs,dBs,vdw=0,vdb=0,sdw=0,sdb=0,optimizer='adam',learn_rate=0.01,beta1=0.9,beta2=0.999,eps=10**-6,t=1):\n",
        "    #W -- list of Weights\n",
        "    #B -- list of Biases\n",
        "    #dW -- list of d/dW\n",
        "    #dB -- list of d/dB\n",
        "    \n",
        "\n",
        "    L=len(Ws)\n",
        "    \n",
        "    if optimizer=='adam' or optimizer=='momentum':\n",
        "        vdw=[beta1*vdw[i]+(1-beta1)*dWs[i] for i in range (L)]\n",
        "        vdb=[beta1*vdb[i]+(1-beta1)*dBs[i] for i in range (L)]\n",
        "        #bias correction\n",
        "        vdw=[vdwi/(1-np.power(beta1,t)) for vdwi in vdw] \n",
        "        vdb=[vdbi/(1-np.power(beta1,t)) for vdbi in vdb]\n",
        "    if optimizer=='adam' or optimizer=='rmsprop':\n",
        "        sdw=[beta2*sdw[i]+(1-beta2)*dWs[i]**2 for i in range(L)]\n",
        "        sdb=[beta2*sdb[i]+(1-beta2)*dBs[i]**2 for i in range(L)]\n",
        "        #bias correction\n",
        "        sdw=[sdwi/(1-np.power(beta2,t))+eps for sdwi in sdw]\n",
        "        sdb=[sdbi/(1-np.power(beta2,t))+eps for sdbi in sdb]\n",
        "    if optimizer=='adam':\n",
        "        Ws=[Ws[i]-learn_rate*vdw[i]/np.sqrt(sdw[i]) for i in range(L)]\n",
        "        Bs=[Bs[i]-learn_rate*vdb[i]/np.sqrt(sdb[i]) for i in range(L)]\n",
        "    if optimizer=='rmsprop':\n",
        "        Ws=[Ws[i]-learn_rate*dWs[i]/np.sqrt(sdw[i]) for i in range(L)]\n",
        "        Bs=[Bs[i]-learn_rate*dBs[i]/np.sqrt(sdb[i]) for i in range(L)]\n",
        "    if optimizer=='momentum':\n",
        "        Bs=[Bs[i]-learn_rate*vdb[i] for i in range(L)]\n",
        "        Ws=[Ws[i]-learn_rate*vdw[i] for i in range(L)]\n",
        "    if optimizer=='sgd':\n",
        "        Bs=[Bs[i]-learn_rate*dBs[i] for i in range(L)]\n",
        "        Ws=[Ws[i]-learn_rate*dWs[i] for i in range(L)]\n",
        "    \n",
        "    \n",
        "    return Ws,Bs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQgVSwman54y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "dee74b1e-fc27-435e-b686-4b44061abeaf"
      },
      "source": [
        "def model(X, Y, layers, optimizer, epochs = 10, lr = 0.001, mini_batch_size = 128,\n",
        "          beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8, middle_activations='relu',last_activation='softmax'):\n",
        "    \"\"\"\n",
        "    3-layer neural network model which can be run in different optimizer modes.\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input data (number of examples, input_size)\n",
        "    Y -- input label (number of examples)\n",
        "    layers -- python list, containing the size of each layer. [input_size,hidden_layer_1,...,hidden_layer_n, output_layer]\n",
        "    optimizer -- a string, one of ['adam','rmsprop','momentum','gd']\n",
        "    epochs -- the number of training epoches\n",
        "    lr -- learning rate, default of 1e-3\n",
        "    mini_batch_size -- the size of a mini batch defaults to 128\n",
        "    beta -- Momentum hyperparameter\n",
        "    beta1 -- Exponential decay hyperparameter for the past gradients estimates \n",
        "    beta2 -- Exponential decay hyperparameter for the past squared gradients estimates \n",
        "    epsilon -- hyperparameter preventing division by zero in Adam updates\n",
        "    middle_activations -- a string, one of ['relu','sigmoid','linear','softmax'], defaults to relu\n",
        "    last_activation -- a string, one of ['relu','sigmoid','linear','softmax'], defaults to softmax\n",
        "\n",
        "    Returns:\n",
        "    Ws,Bs -- Ws- A list of weights [...(ln,ln+1)...], Bs-a list of biases [...(ln+1,1)...] \n",
        "    \"\"\"\n",
        "\n",
        "    L = len(layers)             # number of layers in the neural networks\n",
        "    costs = []                       # to keep track of the cost\n",
        "    t = 1                            # initializing the counter required for Adam update\n",
        "    m = X.shape[0]                   # number of training examples\n",
        "    \n",
        "    # Initialize parameters\n",
        "    \n",
        "    Ws,Bs = initialize_parameters(layers)\n",
        "    vdw=[np.zeros(np.shape(i)) for i in Ws]\n",
        "    vdb=[np.zeros(np.shape(i)) for i in Bs]\n",
        "    sdw=[np.zeros(np.shape(i)) for i in Ws]\n",
        "    sdb=[np.zeros(np.shape(i)) for i in Bs]\n",
        "    minibatches=get_rand_minibatch(X,Y,mini_batch_size)\n",
        "    \n",
        "    \n",
        "    # Optimization loop\n",
        "    for i in range(epochs):\n",
        "        cost_total = 0\n",
        "        \n",
        "        for minibatch in minibatches:\n",
        "\n",
        "            # Select a minibatch\n",
        "            (mini_X, mini_Y) = minibatch\n",
        "\n",
        "            # Forward propagation\n",
        "            As,Zs = forward_prop(Ws,Bs,mini_X,middle_activations='relu',last_activation='softmax')\n",
        "            Yhat=As[-1]\n",
        "\n",
        "            # Compute cost and add to the cost total\n",
        "            cost_total += categorical_crossentropy(mini_Y,Yhat)\n",
        "\n",
        "            # Backward propagation\n",
        "            dWs,dBs = back_prop(Ws,As,mini_Y,Zs,middle_activations='relu',last_activation='linear')\n",
        "\n",
        "            # Optimization step\n",
        "            Ws,Bs=optmize(Ws,Bs,dWs,dBs,vdw,vdb,sdw,sdb,optimizer=optimizer,learn_rate=lr,beta1=beta1,beta2= beta2,eps=epsilon,t=t)\n",
        "            t+=1\n",
        "            \n",
        "        cost = cost_total / m\n",
        "        if i%2==0:\n",
        "            print(cost)\n",
        "        costs.append(cost)\n",
        "                \n",
        "    # plot the cost\n",
        "    plt.plot(costs)\n",
        "    plt.ylabel('cost')\n",
        "    plt.xlabel('epochs')\n",
        "    \n",
        "    plt.title(\"Lr = \" + str(lr))\n",
        "    plt.show()\n",
        "\n",
        "    return Ws,Bs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.06738459239814157\n",
            "0.017447472476796365\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QJOdtUewAIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Ws,Bs=model(train_X, train_Y_oh, layers=[784,12,11,10], optimizer=\"adam\", epochs = 20, lr = 1e-3, mini_batch_size = 64,\n",
        "          beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtINGfTnn542",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(X,Ws,Bs):\n",
        "    \"\"\"Returns a prediction given\n",
        "    X -- a single input\n",
        "    Ws -- a list of weight, [(input_size,layer1),...,(layer n-1,output_size)]\n",
        "    Bs -- a list of biases, [(input_size,1),...,(output_size,1)]\n",
        "    \"\"\"\n",
        "    As,Zs = forward_prop(Ws,Bs,X)\n",
        "    Yhat=As[-1]\n",
        "    prediction=np.argmax(Yhat,axis=-1)\n",
        "    return prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1w7DUbtn544",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "1498f343-233f-4d15-e1d8-039aeb0aedef"
      },
      "source": [
        "idx=555\n",
        "print(predict(test_X[idx,:],Ws,Bs))\n",
        "plt.imshow(np.reshape(test_X[idx,:],(28,28)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc1eb93ce80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "WC7uft-wn548",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c81de762-8754-4f90-a1e3-3f2f3dca8a0c"
      },
      "source": [
        "predicts=predict(train_X,Ws,Bs)\n",
        "acc=np.count_nonzero(predicts==train_Y)/len(train_Y)\n",
        "print(acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7826833333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxkCIz9mn54_",
        "colab_type": "text"
      },
      "source": [
        "#Checking the backpropagation gradient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFZqsgdzn54_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test=train_X[0:2,:]\n",
        "Y_test=train_Y_oh[0:2]\n",
        "Ws,bs=initialize_parameters(layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8taz_Zln55B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "55cefc9b-c7f5-4377-e06c-49984ec8ef4e"
      },
      "source": [
        "\n",
        "As,Zs=forward_prop(Ws,bs,X_test,middle_activations='sigmoid',last_activation='softmax')\n",
        "dWs,dBs=back_prop(Ws,As,Y_test,Zs,middle_activations='sigmoid',last_activation='softmax')\n",
        "\n",
        "\n",
        "\n",
        "eps=1e-6\n",
        "layer=2\n",
        "idx=(2,5)\n",
        "\"\"\"Computing partial derivative\"\"\"\n",
        "Wplus=copy.deepcopy(Ws)\n",
        "Wminus=copy.deepcopy(Ws)\n",
        "Wplus[layer][idx]=Ws[layer][idx]+eps\n",
        "Wminus[layer][idx]=Ws[layer][idx]-eps\n",
        "AsPlus,_=forward_prop(Wplus,bs,X_test,middle_activations='sigmoid',last_activation='softmax')\n",
        "AsMinus,_=forward_prop(Wminus,bs,X_test,middle_activations='sigmoid',last_activation='softmax')\n",
        "Jplus=categorical_crossentropy(Y_test,AsPlus[-1])\n",
        "Jminus=categorical_crossentropy(Y_test,AsMinus[-1])\n",
        "dWtest=(Jplus-Jminus)/(2*eps)\n",
        "\n",
        "\n",
        "print(dWtest,dWs[layer][idx])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-0.4552034247318204 -0.4552034243939695\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}